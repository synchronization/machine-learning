{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fftpack import fft, rfft, irfft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of the features, to be used for making the dataframes\n",
    "\n",
    "# features = ['5KMax', '5KAvg', '5KStd',\n",
    "#             '10KMax', '10KAvg', '10KStd',\n",
    "#             '15KMax', '15KAvg', '15KStd',\n",
    "#             '20KMax', '20KAvg', '20KStd',\n",
    "#             '25KMax', '25KAvg', '25KStd',\n",
    "#             '30KMax', '30KAvg', '30KStd']\n",
    "features = []\n",
    "for i in range(1, 7):\n",
    "    features.append(str(i * 5) + 'KMax')\n",
    "    features.append(str(i * 5) + 'KAvg')\n",
    "    features.append(str(i * 5) + 'KStd')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Chunks FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_freqs_amps(values, T=1):\n",
    "    s = np.array(values.iloc[:, 0])\n",
    "#     t = np.array(values.iloc[:, 1])\n",
    "    fft = np.fft.fft(s)\n",
    "#     T = t[1] - t[0]  # sampling interval \n",
    "    N = s.size\n",
    "#     N = len(s)\n",
    "\n",
    "    # 1/T = frequency\n",
    "    f = np.linspace(0, 1 / T, N)\n",
    "\n",
    "    # frequencies are f[:N // 2]\n",
    "    # amplitudes are np.abs(fft)[:N // 2] * 1 / N\n",
    "    return f[:N // 2], np.abs(fft)[:N // 2] * 1 / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fft_coeffs(values):\n",
    "    rfft_values = rfft(values)\n",
    "\n",
    "#     return [rfft_values[5000], rfft_values[10000], rfft_values[15000], rfft_values[20000]]\n",
    "    result = []\n",
    "    for i in range(1, 7):\n",
    "        result.append(np.amax(rfft_values[0:i * 5000]))\n",
    "        result.append(np.mean(rfft_values[0:i * 5000]))\n",
    "        result.append(np.std(rfft_values[0:i * 5000]))\n",
    "\n",
    "#     return [np.amax(rfft_values[0:5000]),\n",
    "#             np.mean(rfft_values[0:5000]),\n",
    "#             np.amax(rfft_values[5000:10000]),\n",
    "#             np.mean(rfft_values[5000:10000]),\n",
    "#             np.amax(rfft_values[10000:15000]),\n",
    "#             np.mean(rfft_values[10000:15000]),\n",
    "#             np.amax(rfft_values[15000:20000]),\n",
    "#             np.mean(rfft_values[15000:20000]),\n",
    "#             np.amax(rfft_values[20000:25000]),\n",
    "#             np.mean(rfft_values[20000:25000])\n",
    "#            ]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set = pd.read_csv('../data/train/1.csv', float_precision='round_trip')\n",
    "# train_set = pd.read_csv('../data/train/temp-small.csv', float_precision='round_trip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_csvs = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17']\n",
    "# train_set_csvs = ['1', '17']\n",
    "# train_set_csvs = ['1', '2', '3', '4', '5', '6', '7']\n",
    "# train_set_csvs = ['1-small', '2-small', '3-small']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_file_name_full_path = '../data/train/' + '1-small' + '.csv'\n",
    "# temp_train_set = pd.read_csv(csv_file_name_full_path, float_precision='round_trip')\n",
    "# for g, df in temp_train_set.groupby(np.arange(len(temp_train_set)) // 150000):\n",
    "#     print('df.iloc[:, 0]:', list(df.iloc[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed all files ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17']"
     ]
    }
   ],
   "source": [
    "# T = 1.469099981 - 1.4690999799\n",
    "for csv_file_name in train_set_csvs:\n",
    "    csv_file_name_full_path = '../data/train/' + csv_file_name + '.csv'\n",
    "    train_set = pd.read_csv(csv_file_name_full_path, float_precision='round_trip')\n",
    "    \n",
    "    # initialize the DataFrame for this file\n",
    "#     csv_file_stats_df = pd.DataFrame(columns=['Average', 'STD', 'Time_Remained'])\n",
    "#     csv_file_stats_df = pd.DataFrame(columns=['5000', '10000', '15000', '20000', '25000', 'Time_Remained'])\n",
    "    csv_file_stats_df = pd.DataFrame(columns=features+['Time_Remained'])\n",
    "#     csv_file_stats_df = pd.DataFrame()\n",
    "\n",
    "    # we take chunk_size for every training set\n",
    "    # 150K is chosen for this case because the test sizes are the same\n",
    "    chunk_size = 150000\n",
    "    for g, df in train_set.groupby(np.arange(len(train_set)) // chunk_size):\n",
    "#         print('Working on file', csv_file_name, 'chunk', str(g) + '/' + str(len(train_set) // chunk_size))\n",
    "        status_text = '\\rWorking on file ' + \\\n",
    "                      csv_file_name + \\\n",
    "                      ' chunk ' + \\\n",
    "                      str(g) + '/' + str(len(train_set) // chunk_size)\n",
    "        sys.stdout.write(status_text)\n",
    "        sys.stdout.flush()\n",
    "#         freqs, amps = calculate_freqs_amps(df, T)\n",
    "#         c5K, c10K, c15K, c20K = calculate_fft_coeffs(list(df.iloc[:, 0]))\n",
    "        process_result_list = calculate_fft_coeffs(list(df.iloc[:, 0]))\n",
    "    \n",
    "#         avg, std = measures_of_dist(freqs, amps)\n",
    "        time_remained = df.iloc[-1, 1]\n",
    "\n",
    "#         csv_file_stats_df = csv_file_stats_df.append({'Average': avg,\n",
    "#                                                       'STD': std,\n",
    "#                                                       'Time_Remained': time_remained},\n",
    "#                                                      ignore_index=True)\n",
    "#         csv_file_stats_df = csv_file_stats_df.append({'5000': c5K,\n",
    "#                                                       '10000': c10K,\n",
    "#                                                       '15000': c15K,\n",
    "#                                                       '20000': c20K,\n",
    "#                                                       'Time_Remained': time_remained},\n",
    "#                                                      ignore_index=True)\n",
    "#         print('process_result_list + [time_remained]:', process_result_list + [time_remained])\n",
    "#         print('Before append, csv_file_stats_df:', csv_file_stats_df)\n",
    "#         print('csv_file_stats_df.columns:', csv_file_stats_df.columns)\n",
    "        csv_file_stats_df = csv_file_stats_df.append(pd.Series(process_result_list + [time_remained],\n",
    "                                                               index=csv_file_stats_df.columns),\n",
    "                                                     ignore_index=True)\n",
    "\n",
    "#         print('After append, csv_file_stats_df:', csv_file_stats_df)\n",
    "        \n",
    "    chunk_stats_file_name = 'chunk_stats_' + csv_file_name + '.pkl'\n",
    "    csv_file_stats_df.to_pickle(chunk_stats_file_name)\n",
    "    \n",
    "# print('-------------------------')\n",
    "# print()\n",
    "# print('Completed all files', train_set_csvs)\n",
    "sys.stdout.write('\\rCompleted all files ' + str(train_set_csvs))\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_avg_std_time_remained = pd.DataFrame(columns=['Average', 'STD', 'Time_Remained'])\n",
    "# results_process_and_time_remained = pd.DataFrame(columns=['5000',\n",
    "#                                                           '10000',\n",
    "#                                                           '15000',\n",
    "#                                                           '20000',\n",
    "#                                                           '25000',\n",
    "#                                                           'Time_Remained'])\n",
    "results_process_and_time_remained = pd.DataFrame(columns=features+['Time_Remained'])\n",
    "# results_process_and_time_remained = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for csv_file_name in train_set_csvs:\n",
    "    df_file_name = 'chunk_stats_' + csv_file_name + '.pkl'\n",
    "    chunk_df = pd.read_pickle(df_file_name)\n",
    "#     results_avg_std_time_remained = results_avg_std_time_remained.append(chunk_df, ignore_index=True)\n",
    "    results_process_and_time_remained = results_process_and_time_remained.append(chunk_df,\n",
    "                                                                                 ignore_index=True,\n",
    "                                                                                 sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5KMax</th>\n",
       "      <th>5KAvg</th>\n",
       "      <th>5KStd</th>\n",
       "      <th>10KMax</th>\n",
       "      <th>10KAvg</th>\n",
       "      <th>10KStd</th>\n",
       "      <th>15KMax</th>\n",
       "      <th>15KAvg</th>\n",
       "      <th>15KStd</th>\n",
       "      <th>20KMax</th>\n",
       "      <th>20KAvg</th>\n",
       "      <th>20KStd</th>\n",
       "      <th>25KMax</th>\n",
       "      <th>25KAvg</th>\n",
       "      <th>25KStd</th>\n",
       "      <th>30KMax</th>\n",
       "      <th>30KAvg</th>\n",
       "      <th>30KStd</th>\n",
       "      <th>Time_Remained</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>732610.0</td>\n",
       "      <td>143.912367</td>\n",
       "      <td>10405.942700</td>\n",
       "      <td>732610.0</td>\n",
       "      <td>70.968719</td>\n",
       "      <td>7477.516039</td>\n",
       "      <td>732610.0</td>\n",
       "      <td>45.750652</td>\n",
       "      <td>6466.661873</td>\n",
       "      <td>732610.0</td>\n",
       "      <td>32.045722</td>\n",
       "      <td>6084.374964</td>\n",
       "      <td>732610.0</td>\n",
       "      <td>26.529029</td>\n",
       "      <td>5538.165517</td>\n",
       "      <td>732610.0</td>\n",
       "      <td>19.088657</td>\n",
       "      <td>5083.794709</td>\n",
       "      <td>1.430797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>708865.0</td>\n",
       "      <td>133.813010</td>\n",
       "      <td>10136.272301</td>\n",
       "      <td>708865.0</td>\n",
       "      <td>64.531599</td>\n",
       "      <td>7544.161357</td>\n",
       "      <td>708865.0</td>\n",
       "      <td>52.472938</td>\n",
       "      <td>6721.103958</td>\n",
       "      <td>708865.0</td>\n",
       "      <td>44.389343</td>\n",
       "      <td>6640.187394</td>\n",
       "      <td>708865.0</td>\n",
       "      <td>33.431662</td>\n",
       "      <td>6084.912397</td>\n",
       "      <td>708865.0</td>\n",
       "      <td>29.982647</td>\n",
       "      <td>5583.991456</td>\n",
       "      <td>1.391499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>735959.0</td>\n",
       "      <td>193.665903</td>\n",
       "      <td>10504.359311</td>\n",
       "      <td>735959.0</td>\n",
       "      <td>108.423915</td>\n",
       "      <td>7890.204148</td>\n",
       "      <td>735959.0</td>\n",
       "      <td>68.295336</td>\n",
       "      <td>7004.419740</td>\n",
       "      <td>735959.0</td>\n",
       "      <td>51.984008</td>\n",
       "      <td>6970.667037</td>\n",
       "      <td>735959.0</td>\n",
       "      <td>33.586423</td>\n",
       "      <td>6387.759858</td>\n",
       "      <td>735959.0</td>\n",
       "      <td>21.091974</td>\n",
       "      <td>5863.191283</td>\n",
       "      <td>1.353196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>735343.0</td>\n",
       "      <td>152.570859</td>\n",
       "      <td>10612.815371</td>\n",
       "      <td>735343.0</td>\n",
       "      <td>77.799647</td>\n",
       "      <td>8164.249430</td>\n",
       "      <td>735343.0</td>\n",
       "      <td>41.854227</td>\n",
       "      <td>7050.315632</td>\n",
       "      <td>735343.0</td>\n",
       "      <td>27.278968</td>\n",
       "      <td>6969.794936</td>\n",
       "      <td>735343.0</td>\n",
       "      <td>19.629223</td>\n",
       "      <td>6366.904849</td>\n",
       "      <td>735343.0</td>\n",
       "      <td>15.943259</td>\n",
       "      <td>5845.388882</td>\n",
       "      <td>1.313798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>736310.0</td>\n",
       "      <td>129.797777</td>\n",
       "      <td>10508.454710</td>\n",
       "      <td>736310.0</td>\n",
       "      <td>61.205543</td>\n",
       "      <td>8503.581755</td>\n",
       "      <td>736310.0</td>\n",
       "      <td>46.405526</td>\n",
       "      <td>7536.030122</td>\n",
       "      <td>736310.0</td>\n",
       "      <td>46.532470</td>\n",
       "      <td>7186.499562</td>\n",
       "      <td>736310.0</td>\n",
       "      <td>36.138594</td>\n",
       "      <td>6558.105892</td>\n",
       "      <td>736310.0</td>\n",
       "      <td>33.938496</td>\n",
       "      <td>6020.034317</td>\n",
       "      <td>1.274400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      5KMax       5KAvg         5KStd    10KMax      10KAvg       10KStd  \\\n",
       "0  732610.0  143.912367  10405.942700  732610.0   70.968719  7477.516039   \n",
       "1  708865.0  133.813010  10136.272301  708865.0   64.531599  7544.161357   \n",
       "2  735959.0  193.665903  10504.359311  735959.0  108.423915  7890.204148   \n",
       "3  735343.0  152.570859  10612.815371  735343.0   77.799647  8164.249430   \n",
       "4  736310.0  129.797777  10508.454710  736310.0   61.205543  8503.581755   \n",
       "\n",
       "     15KMax     15KAvg       15KStd    20KMax     20KAvg       20KStd  \\\n",
       "0  732610.0  45.750652  6466.661873  732610.0  32.045722  6084.374964   \n",
       "1  708865.0  52.472938  6721.103958  708865.0  44.389343  6640.187394   \n",
       "2  735959.0  68.295336  7004.419740  735959.0  51.984008  6970.667037   \n",
       "3  735343.0  41.854227  7050.315632  735343.0  27.278968  6969.794936   \n",
       "4  736310.0  46.405526  7536.030122  736310.0  46.532470  7186.499562   \n",
       "\n",
       "     25KMax     25KAvg       25KStd    30KMax     30KAvg       30KStd  \\\n",
       "0  732610.0  26.529029  5538.165517  732610.0  19.088657  5083.794709   \n",
       "1  708865.0  33.431662  6084.912397  708865.0  29.982647  5583.991456   \n",
       "2  735959.0  33.586423  6387.759858  735959.0  21.091974  5863.191283   \n",
       "3  735343.0  19.629223  6366.904849  735343.0  15.943259  5845.388882   \n",
       "4  736310.0  36.138594  6558.105892  736310.0  33.938496  6020.034317   \n",
       "\n",
       "   Time_Remained  \n",
       "0       1.430797  \n",
       "1       1.391499  \n",
       "2       1.353196  \n",
       "3       1.313798  \n",
       "4       1.274400  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results_avg_std_time_remained\n",
    "results_process_and_time_remained.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = results_avg_std_time_remained[['Average', 'STD']]\n",
    "# X = results_process_and_time_remained[['5000', '10000', '15000', '20000', '25000']]\n",
    "X = results_process_and_time_remained[features]\n",
    "# y = results_avg_std_time_remained[['Time_Remained']]\n",
    "y = results_process_and_time_remained[['Time_Remained']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lm.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 14.72 %\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save to file in the current working directory\n",
    "pkl_filename = \"pickle_model_1_to_17.pkl\"\n",
    "# pkl_filename = \"pickle_model_1_and_17.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "# Load from file\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    pickle_model = pickle.load(file)\n",
    "\n",
    "# Calculate the accuracy score and predict target values\n",
    "score = pickle_model.score(X, y)\n",
    "print(\"Test score: {0:.2f} %\".format(100 * score))\n",
    "Ypredict = pickle_model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sets = pd.read_csv('../data/sample_submission.csv')\n",
    "# test_sets = pd.read_csv('../data/sample_submission_tiny.csv')\n",
    "total_test_sets = len(test_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_csv_file_name = '../data/tests/' + 'seg_ffe7cc.csv'\n",
    "# test_set = pd.read_csv(test_csv_file_name)\n",
    "# test_set.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed writing the results to ../data/result_submission.csv"
     ]
    }
   ],
   "source": [
    "evaluation_results_df = pd.DataFrame(columns=['seg_id', 'time_to_failure'])\n",
    "# T = 1.469099981 - 1.4690999799\n",
    "for index, row in test_sets.iterrows():\n",
    "#     print('----------------')\n",
    "#     print('Evaluating test', str(index) + '/' + str(total_test_sets))\n",
    "    sys.stdout.write('\\rEvaluating test ' + \\\n",
    "                     str(row['seg_id']) + \\\n",
    "                     ' (' + \\\n",
    "                     str(index) + \\\n",
    "                     '/' + \\\n",
    "                     str(total_test_sets) + \\\n",
    "                     ')')\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    test_csv_file_name = '../data/tests/' + row['seg_id'] + '.csv'\n",
    "    test_set = pd.read_csv(test_csv_file_name)\n",
    "    test_set.head(5)\n",
    "    \n",
    "    X = test_set[['acoustic_data']]\n",
    "    \n",
    "#     freqs, amps = calculate_freqs_amps(X, T)\n",
    "#     avg, std = measures_of_dist(freqs, amps)\n",
    "#     c5K, c10K, c15K, c20K, c25K = calculate_fft_coeffs(X.iloc[:, 0])\n",
    "    process_result_list = calculate_fft_coeffs(X.iloc[:, 0])\n",
    "#     c5K, c10K, c15K, c20K = calculate_fft_coeffs(X[:, 0])\n",
    "    \n",
    "#     Ypredict = pickle_model.predict([[c5K, c10K, c15K, c20K, c25K]])\n",
    "    Ypredict = pickle_model.predict([process_result_list])\n",
    "    \n",
    "    evaluation_results_df = evaluation_results_df.append({'seg_id': row['seg_id'],\n",
    "                                                          'time_to_failure': Ypredict[0][0]},\n",
    "                                                          ignore_index=True)\n",
    "\n",
    "evaluation_results_df.to_csv('../data/result_submission.csv', index=False)\n",
    "# evaluation_results_df.to_csv('../data/result_submission_tiny.csv', index=False)\n",
    "# print('Completed writing the results to ../data/result_submission.csv')\n",
    "sys.stdout.write('\\rCompleted writing the results to ../data/result_submission.csv')\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with FFT Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fftpack import fft\n",
    "# Number of samplepoints\n",
    "N = 600\n",
    "# sample spacing\n",
    "T = 1.0 / 800.0\n",
    "x = np.linspace(0.0, N*T, N)\n",
    "y = np.sin(50.0 * 2.0*np.pi*x) + 0.5*np.sin(80.0 * 2.0*np.pi*x)\n",
    "yf = fft(y)\n",
    "xf = np.linspace(0.0, 1.0/(2.0*T), N//2)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(xf, 2.0/N * np.abs(yf[0:N//2]))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import argrelmax\n",
    "\n",
    "f = xf[scipy.signal.argrelmax(yf[0:N//2])]\n",
    "Af = np.abs(yf[argrelmax(yf[0:N//2])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1.0, 2.0, 1.0, -1.0, 1.5, 1.0])\n",
    "fft_x = fft(x)\n",
    "print('fft_x:', fft_x)\n",
    "\n",
    "yr = rfft(x)\n",
    "print('yr:', yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(0, 0.5, 500)\n",
    "s = np.sin(10 * 2 * np.pi * t) + 0.5 * np.sin(30 * 2 * np.pi * t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfft_s = rfft(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rfft_s[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with Simple FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(256)\n",
    "sp = np.fft.fft(np.sin(t))\n",
    "freq = np.fft.fftfreq(t.shape[-1])\n",
    "# plt.plot(freq, sp.real, freq, sp.imag)\n",
    "# plt.plot(freq, sp.real)\n",
    "plt.plot(freq, abs(sp))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(0, 0.5, 500)\n",
    "s = np.sin(40 * 2 * np.pi * t) + 0.5 * np.sin(90 * 2 * np.pi * t)\n",
    "\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.plot(t, s)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft = np.fft.fft(s)\n",
    "T = t[1] - t[0]  # sampling interval \n",
    "N = s.size\n",
    "\n",
    "# 1/T = frequency\n",
    "f = np.linspace(0, 1 / T, N)\n",
    "\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.xlabel(\"Frequency [Hz]\")\n",
    "plt.bar(f[:N // 2], np.abs(fft)[:N // 2] * 1 / N, width=1.5)  # 1 / N is a normalization factor\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(f[:N // 2], np.abs(fft)[:N // 2] * 1 / N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.abs(fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# f[:N // 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# np.abs(fft)[:N // 2] * 1 / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [1, 2, 3, 4]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.average([1, 2, 3, 4], weights=[10, 1, 1, 1])\n",
    "np.average(np.abs(fft), weights=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measures_of_dist(weights, values):\n",
    "    \"\"\"\n",
    "    Return the weighted average and standard deviation.\n",
    "\n",
    "    values, weights -- Numpy ndarrays with the same shape.\n",
    "    \"\"\"\n",
    "    average = np.average(values, weights=weights)\n",
    "    # Fast and numerically precise:\n",
    "    variance = np.average((values-average)**2, weights=weights)\n",
    "    \n",
    "    return average, math.sqrt(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m, s = measures_of_dist([1, 2, 3, 4], [10, 1, 1, 1])\n",
    "m, s = measures_of_dist(np.abs(fft), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.469099981 - 1.4690999799"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l ../data/train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time train_set = pd.read_csv('../data/train/1.csv', skiprows=None, nrows=5656574)\n",
    "train_set = pd.read_csv('../data/train/1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "# import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_set.iloc[4400000:4500000, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = train_set.iloc[0:5000, 0]\n",
    "x = train_set.iloc[0:150000, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, t, Zxx = signal.stft(x, nperseg=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.pcolormesh(t, f, np.abs(Zxx), cmap=\"binary\")\n",
    "plt.colorbar()\n",
    "plt.title('STFT Magnitude')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfft_values = rfft(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(rfft_values[1:25000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Zxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Zxx[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0.0, 1.0, 2.0, 3.0,  4.0,  5.0])\n",
    "y = np.array([0.0, 0.8, 0.9, 0.1, -0.8, -1.0])\n",
    "z = np.polyfit(x, y, 3)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "#     print('i:', i)\n",
    "    sys.stdout.write(\"\\rDoing thing %i\" % i)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
